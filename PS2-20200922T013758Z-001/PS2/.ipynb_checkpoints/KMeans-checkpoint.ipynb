{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Color quantization k-means\n",
    "\n",
    "For this problem you will write code to quantize a color space by applying k-means clustering to the pixels in a given input image. We will experiment with two different color spaces — RGB and HSV.\n",
    "\n",
    "Implement each of the functions described below. After each function there is a test on the 4x6 image that will be generated within this notebook. These test are to help you verify and debug your code. However, they will not cover every possible edge case. We encourage you to write additional test or debug your code line-by-line to make sure the functions work as expected.\n",
    "\n",
    "> Note: to pass the tests in this notebook and on Gradescope you will need to use a random seed value of `101` whenever possible. Please check the docstrings for any of the 3rd party functions to make sure you set the random seed properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting this notebook to a .py script\n",
    "\n",
    "Once you are done implementing all the required functions in this notebook, you can go ahead and use the provided `notebook2script.py` script to convert this notebook into a `.py` file for submission.\n",
    "\n",
    "The provided script will look for all the cells with the `#export` tag in the first line of the cell and only add those cells to the final script. This tag is already present for all the required cells in this notebook.\n",
    "\n",
    "If you add any cells that you want to include in the submission, you can add the tag to the top of the cell.\n",
    "\n",
    "The idea behind this is that students get to experiment, print and plot freely in the notebook while ensuring the submission file remains Gradescope friendly. Please avoid putting the `#export` tag on cells with `print`, `imshow`, and `plot` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aed28c895104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrgb2hsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhsv2rgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.color import rgb2hsv, hsv2rgb\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commands in the follwing cell will plot all images/plots in an interactive window. If you would prefer to not have interactive plots, comment out %matplotlib notebook and uncomment %matplotlib inline instead.\n",
    "\n",
    "You can use plt.rcParams['figure.figsize'] to make all the plots in this notebook bigger or smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = (7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set test_k = 4 to pass the tests in this notebook\n",
    "test_k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate a random test image (with a seed of `101`)\n",
    "np.random.seed(101)\n",
    "test_img = np.random.randint(0, 256, size=(4, 6, 3), dtype=np.uint8)\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Quantize in RGB space\n",
    "\n",
    "Given an RGB image, quantize the 3-dimensional RGB space, and map each pixel in the input image to its nearest k-means center. That is, replace the RGB value at each pixel with its nearest cluster’s average RGB value.\n",
    "\n",
    "Use the [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) class to perfom the k-means clustering. See the documentation for details on how to use the class, and make sure you set `random_state=101`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def quantize_rgb(img: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the k-means clusters for the input image in RGB space, and return\n",
    "    an image where each pixel is replaced by the nearest cluster's average RGB\n",
    "    value.\n",
    "\n",
    "    Inputs:\n",
    "        img: Input RGB image with shape H x W x 3 and dtype \"uint8\"\n",
    "        k: The number of clusters to use\n",
    "\n",
    "    Output:\n",
    "        An RGB image with shape H x W x 3 and dtype \"uint8\"\n",
    "    \"\"\"\n",
    "    quantized_img = np.zeros_like(img)\n",
    "    \n",
    "    ##########################################################################\n",
    "    # TODO: Perfom k-means clustering and return an image where each pixel   #\n",
    "    # is assigned the value of the nearest clusters RGB values.              #\n",
    "    ##########################################################################\n",
    "    \n",
    "    samples = img.reshape((-1, img.shape[2]))\n",
    "    print(\"sample size is\",np.shape(samples))\n",
    "    kMeans = KMeans(n_clusters=k, random_state=101)\n",
    "    labels = kMeans.fit_predict(samples)\n",
    "    centers = kMeans.cluster_centers_\n",
    "    quantized_img = centers[labels].reshape(img.shape).astype(np.uint8)\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    \n",
    "    return quantized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_quantized_img_rgb = np.array([[[159, 173,  49],\n",
    "        [ 80,  34,  60],\n",
    "        [159, 173,  49],\n",
    "        [ 99,  60, 190],\n",
    "        [ 99,  60, 190],\n",
    "        [159, 173,  49]],\n",
    "\n",
    "       [[ 80,  34,  60],\n",
    "        [ 99,  60, 190],\n",
    "        [209, 185, 212],\n",
    "        [ 80,  34,  60],\n",
    "        [ 99,  60, 190],\n",
    "        [ 99,  60, 190]],\n",
    "\n",
    "       [[ 99,  60, 190],\n",
    "        [159, 173,  49],\n",
    "        [159, 173,  49],\n",
    "        [ 80,  34,  60],\n",
    "        [ 99,  60, 190],\n",
    "        [ 99,  60, 190]],\n",
    "\n",
    "       [[209, 185, 212],\n",
    "        [209, 185, 212],\n",
    "        [159, 173,  49],\n",
    "        [ 80,  34,  60],\n",
    "        [209, 185, 212],\n",
    "        [ 99,  60, 190]]], dtype=np.uint8)\n",
    "\n",
    "quantized_img_rgb = quantize_rgb(test_img, test_k)\n",
    "\n",
    "if np.allclose(quantized_img_rgb, expected_quantized_img_rgb):\n",
    "    print(\"\\nQuantized image computed correctly!\")\n",
    "else:\n",
    "    print(\"\\nQuantized image is incorrect.\")\n",
    "    print(f\"\\nexpected:\\n\\n{expected_quantized_img_rgb}\")\n",
    "    print(f\"\\ncomputed:\\n\\n{quantized_img_rgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].imshow(test_img)\n",
    "\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].imshow(quantized_img_rgb)\n",
    "\n",
    "# uncomment this line and change the filename as needed to save the figure\n",
    "# fig.savefig(f\"output-quantized-rgb-{k}.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Quantize in HSV space\n",
    "\n",
    "Given an RGB image, convert it to HSV and quantize the 1-dimensional Hue space. Map each pixel in the input image to its nearest quantized Hue value, while keeping its Saturation and Value channels the same as the input. Convert the quantized output back to RGB color space.\n",
    "\n",
    "Use the [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) class to perfom the k-means clustering. See the documentation for details on how to use the class, and make sure you set `random_state=101`.\n",
    "\n",
    "Use the [skimage.color.rgb2hsv](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.rgb2hsv) and [skimage.color.hsv2rgb](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.hsv2rgb) functions to convert the image to HSV and back to RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def quantize_hsv(img: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the k-means clusters for the input image in the hue dimension of the\n",
    "    HSV space. Replace the hue values with the nearest cluster's hue value. Finally,\n",
    "    convert the image back to RGB.\n",
    "    \n",
    "    Inputs:\n",
    "        img: Input RGB image with shape H x W x 3 and dtype \"uint8\"\n",
    "        k: The number of clusters to use\n",
    "\n",
    "    Output:\n",
    "        An RGB image with shape H x W x 3 and dtype \"uint8\"\n",
    "    \"\"\"\n",
    "    quantized_img = np.zeros_like(img)\n",
    "\n",
    "    ##########################################################################\n",
    "    # TODO: Convert the image to HSV. Perfom k-means clustering in hue       #\n",
    "    # space. Replace the hue values in the image with the cluster centers.   #\n",
    "    # Convert the image back to RGB.                                         #\n",
    "    ##########################################################################\n",
    "    \n",
    "    hsv_img = rgb2hsv(img)\n",
    "    hsv_hue = hsv_img[:,:,0]\n",
    "    samples = hsv_hue.reshape((-1, 1))\n",
    "    kMeans = KMeans(n_clusters=k, random_state=101)\n",
    "    labels = kMeans.fit_predict(samples)\n",
    "    centers = kMeans.cluster_centers_\n",
    "    hsv_img[:,:,0] = centers[labels].reshape(hsv_hue.shape)\n",
    "    quantized_img = (hsv2rgb(hsv_img) * 255).astype(np.uint8)\n",
    "    \n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    return quantized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_quantized_img_hsv = np.array([[[ 94, 179,  49],\n",
    "        [131,  11, 112],\n",
    "        [101, 141,  81],\n",
    "        [ 38,  23, 146],\n",
    "        [ 55,  31, 227],\n",
    "        [243, 166,  22]],\n",
    "\n",
    "       [[ 87,   7,  74],\n",
    "        [252,   3, 212],\n",
    "        [253, 215, 246],\n",
    "        [ 54,  75,  43],\n",
    "        [ 29,   0, 239],\n",
    "        [ 90,  79, 175]],\n",
    "\n",
    "       [[132, 125, 187],\n",
    "        [114, 205,  66],\n",
    "        [ 99, 213,  40],\n",
    "        [ 86,  17,  75],\n",
    "        [149,  86, 139],\n",
    "        [ 72,  63, 138]],\n",
    "\n",
    "       [[192, 147, 184],\n",
    "        [199, 195, 227],\n",
    "        [245, 172,  36],\n",
    "        [ 68,  53,  24],\n",
    "        [187, 183, 220],\n",
    "        [ 68,  49, 199]]], dtype=np.uint8)\n",
    "\n",
    "quantized_img_hsv = quantize_hsv(test_img, test_k)\n",
    "\n",
    "if np.allclose(quantized_img_hsv, expected_quantized_img_hsv):\n",
    "    print(\"\\nQuantized image computed correctly!\")\n",
    "else:\n",
    "    print(\"\\nQuantized image is incorrect.\")\n",
    "    print(f\"\\nexpected:\\n\\n{expected_quantized_img_hsv}\")\n",
    "    print(f\"\\ncomputed:\\n\\n{quantized_img_hsv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].imshow(test_img)\n",
    "\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].imshow(quantized_img_hsv)\n",
    "\n",
    "# uncomment this line and change the filename as needed to save the figure\n",
    "# fig.savefig(f\"output-quantized-hsv-{k}.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Sum of squared error\n",
    "\n",
    "Write a function to compute the SSD error (sum of squared error) between the original RGB pixel values and the quantized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_quantization_error(img: np.ndarray, quantized_img: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Compute the sum of squared error between the two input images.\n",
    "\n",
    "    Inputs:\n",
    "        img: Input RGB image with shape H x W x 3 and dtype \"uint8\"\n",
    "        quantized_img: Quantized RGB image with shape H x W x 3 and dtype \"uint8\"\n",
    "\n",
    "    Output:\n",
    "    \n",
    "    \"\"\"\n",
    "    error = 0\n",
    "\n",
    "    ##########################################################################\n",
    "    # TODO: Compute the sum of squared error.                                #\n",
    "    ##########################################################################\n",
    "\n",
    "    error = np.sum((quantized_img.astype(int) - img.astype(int))**2)\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rgb = compute_quantization_error(test_img, quantized_img_rgb)\n",
    "print(f\"quantization error (rgb): {error_rgb:,}\")\n",
    "\n",
    "error_hsv = compute_quantization_error(test_img, quantized_img_hsv)\n",
    "print(f\"quantization error (hsv): {error_hsv:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if error_rgb == 112251:\n",
    "    print(\"\\nQuantization error computed correctly!\")\n",
    "else:\n",
    "    print(\"\\nQuantization error incorrect\")\n",
    "    print(f\"\\nexpected: 112,251\\ncomputed: {error_rgb}\")\n",
    "\n",
    "\n",
    "if error_hsv == 33167:\n",
    "    print(\"\\nQuantization error computed correctly!\")\n",
    "else:\n",
    "    print(\"\\nQuantization error incorrect\")\n",
    "    print(f\"\\nexpected: 33,167\\ncomputed: {error_hsv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Calculate Hue histograms\n",
    "\n",
    "Given an image, compute and display two histograms of its hue values. Let the first histogram use equally-spaced bins (uniformly dividing up the hue values), and let the second histogram use bins defined by the `k` cluster center memberships (i.e., all pixels belonging to hue cluster `i` go to the `i-th` bin, for `i=1,...k`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_hue_histograms(img: np.ndarray, k: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the histogram values two ways: equally spaced and clustered.\n",
    "    \n",
    "    Inputs:\n",
    "        img: Input RGB image with shape H x W x 3 and dtype \"uint8\"\n",
    "        k: The number of clusters to use\n",
    "\n",
    "    Output:\n",
    "        hist_equal: The values for an equally spaced histogram\n",
    "        hist_clustered: The values for a histogram of the cluster assignments\n",
    "    \"\"\"\n",
    "    hist_equal = np.zeros((k,), dtype=np.int64)\n",
    "    hist_clustered = np.zeros((k,), dtype=np.int64)\n",
    "\n",
    "    ##########################################################################\n",
    "    # TODO: Convert the image to HSV. Calculate a k-bin histogram for the    #\n",
    "    # hue dimension. Calculate the k-means clustering of the hue space.      #\n",
    "    # Calculate the histogram values for the cluster assignments.            #\n",
    "    ##########################################################################\n",
    "\n",
    "    hsv_img = rgb2hsv(img)\n",
    "    hsv_hue = hsv_img[:, :, 0]\n",
    "    hist_equal, _ = np.histogram(hsv_hue, bins=k)\n",
    "    \n",
    "    samples = hsv_hue.reshape((-1, 1))\n",
    "    kMeans = KMeans(n_clusters=k, random_state=101)\n",
    "    labels = kMeans.fit_predict(samples)\n",
    "    hist_clustered, _ = np.histogram(labels, bins=k)\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    \n",
    "    return hist_equal, hist_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_hist_equal = np.array([ 6,  2,  6, 10], dtype=np.int64)\n",
    "expected_hist_clustered = np.array([3, 9, 7, 5], dtype=np.int64)\n",
    "\n",
    "hist_equal, hist_clustered = get_hue_histograms(test_img, test_k)\n",
    "\n",
    "if np.all(hist_equal == expected_hist_equal):\n",
    "    print(\"\\nEqual histogram values computed correctly!\")\n",
    "else:\n",
    "    print(\"\\nEqual histogram values are incorrect.\")\n",
    "    print(f\"\\nexpected: {expected_hist_equal}\")\n",
    "    print(f\"\\ncomputed: {hist_equal}\")\n",
    "    \n",
    "if np.all(hist_clustered == expected_hist_clustered):\n",
    "    print(\"\\nClustered histogram values computed correctly!\")\n",
    "else:\n",
    "    print(\"\\nClustered histogram values are incorrect.\")\n",
    "    print(f\"\\nexpected: {expected_hist_clustered}\")\n",
    "    print(f\"\\ncomputed: {hist_clustered}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].set_title(\"equal\")\n",
    "axs[0].bar(np.arange(test_k), hist_equal)\n",
    "\n",
    "axs[1].set_title(\"clustered\")\n",
    "axs[1].bar(np.arange(test_k), hist_clustered)\n",
    "\n",
    "# uncomment this line and change the filename as needed to save the figure\n",
    "# fig.savefig(f\"output-histograms-{k}.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Once you are ready to submit, you can run the following cell to export this notebook into a Python script. You should submit this script to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "\n",
    "fish = np.array(imread('./fish.jpg'))\n",
    "K = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_rgb_quantized = quantize_rgb(fish, k=K)\n",
    "_, ax = plt.subplots()\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(fish_rgb_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_hsv_quantized = quantize_hsv(fish, k=K)\n",
    "_, ax = plt.subplots()\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(fish_hsv_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('RGB-Quantization SSD Error, K={}:'.format(K), compute_quantization_error(fish, fish_rgb_quantized))\n",
    "print('HSV-Quantization SSD Error, K={}:'.format(K), compute_quantization_error(fish, fish_hsv_quantized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_equal, hist_clustered = get_hue_histograms(fish, K)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "plt.subplots_adjust(wspace = 0.4)\n",
    "axs[0].set_title(\"equal\")\n",
    "axs[0].set_xlabel(\"bin ID\")\n",
    "axs[0].set_ylabel(\"number of pixels\")\n",
    "axs[0].bar(np.arange(K), hist_equal)\n",
    "\n",
    "axs[1].set_title(\"clustered\")\n",
    "axs[1].set_xlabel(\"cluster ID\")\n",
    "axs[1].set_ylabel(\"number of pixels\")\n",
    "axs[1].bar(np.arange(K), hist_clustered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the two forms of histogram differ?\n",
    "\n",
    "The two forms of histograms differ in terms of the sizes/ranges of bins. Both histograms display results of the hue space, but $\\textbf{hist_equal}$ divides the hue space into $k$ equally-sized bins, whereas the $\\textbf{hist_clustered}$ creates bins based on the clustereing results with $k$ clusters. The later has bins of that are not necessarily equally spaced, meaning some bins may have ranges larger than other bins.\n",
    "\n",
    "How and why do results vary depending on the color space?\n",
    "\n",
    "The results on images differ because the functions `quantize_rgb` and `quantize_hsv` opperate differently. `quantize_rgb` quantizes the images to have only $k$ RGB colors. On the contrary, `quantize_hsv` only quantizes the hue channel into $k$ values but leaves the brightness and saturation unaffected, resulting in more possible RGB values when converted to RGB images. In other words, for `quantize_rgb`, k corresponds to the number of colors, but for `quantize_hsv`, k only corresponds to number of hues.\n",
    "\n",
    "The value of k?\n",
    "\n",
    "As we increase the value of k, the SSD between the original image and the quantized ones dropped for both `quantize_rgb` and `quantized_hsv`. This is expected because adding more cluster centers would result in some data points become closer to one of the cluster centers. In the original image, the effect would be having pixels values more similar to that of the original image, thus lowering SSD.\n",
    "\n",
    "Increasing the value of k would also make both images to look more similar to the original input image since we are allowed to have more representative colors. Meanwhile, the histograms also tend display more details: we can now observe some ranges of hues are much more frequent in the image than some others, because the distributions becomre more uneven.\n",
    "\n",
    "Across different runs?\n",
    "\n",
    "The results are consitent each time with a fixed random seed, and changing the value of k does not affect the trends we have observed. In particular, we can see the SSD for `quantize_hsv` is almost always lower than `quantize_rgb` because the former generally allows more RGB values than the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
