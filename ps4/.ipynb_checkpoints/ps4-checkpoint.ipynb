{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Programming problem [75 points]\n",
    "\n",
    "\n",
    "For this problem, you will implement a video search method to retrieve relevant frames from a video\n",
    "based on the features in a query region selected from some frame. We are providing image data and some\n",
    "starter code for this assignment.\n",
    "\n",
    "## Provided data\n",
    "\n",
    "You can access pre–computed SIFT features here: https://filebox.ece.vt.edu/~F13ECE5554/resources/PS4_material/PS4SIFT.zip.\n",
    "\n",
    "The associated images are stored here: https://filebox.ece.vt.edu/~F13ECE5554/resources/PS4_material/PS4Frames.zip.\n",
    "\n",
    "Please note that the data takes about 6GB. Each .mat file in the provided SIFT data corresponds to a single\n",
    "image, and contains the following variables, where `N` is the number of detected SIFT features in that image:\n",
    "\n",
    "|   | shape | type | description |\n",
    "|:-:|:-----:|:----:|:-----------:|\n",
    "| descriptors | Nx128 | double | the SIFT vectors as rows |\n",
    "| imname | 1x57 | char | name of the image file that goes with this data |\n",
    "| numfeats | 1x1 | double | number of detected features |\n",
    "| orients | Nx1 | double | the orientations of the patches |\n",
    "| positions | Nx2 | double | the positions of the patch centers |\n",
    "| scales | Nx1 | double | the scales of the patches |\n",
    "\n",
    "## Provided code\n",
    "\n",
    "The following are the provided code files. You are not required to use any of these functions, but you will\n",
    "probably find them helpful.\n",
    "\n",
    "**loadDataExample.py**: Run this code first and make sure you understand the data format. It is\n",
    "a script that selects a random image, and shows how to access the descriptors. It also shows how to use\n",
    "some of the other functions below.\n",
    "\n",
    "**displaySIFTPatches.py**: given SIFT descriptor info, it returns the corners corresponding to each patch.\n",
    "\n",
    "**getPatchFromSIFTParameters.py**: given SIFT descriptor info, it extracts the image patch itself and\n",
    "returns as a single image\n",
    "\n",
    "**selectRegion.py**: given an image and list of feature positions, it allows a user to draw a polygon\n",
    "showing a region of interest, and then returns the indices within the list of positions that fell within\n",
    "the polygon.\n",
    "\n",
    "**dist2.py**: a fast implementation of computing pairwise distances between two matrices for which each\n",
    "row is a data point\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "After completing all four parts of this notebook manually export the following functions into a file name `ps4.py`:\n",
    "\n",
    "- [ ] `match_descriptors()`\n",
    "- [ ] `calculate_bag_of_words_histogram()`\n",
    "- [ ] `caculate_normalized_scalar_product()`\n",
    "\n",
    "> Note: You must include all of the imports required by your functions in the file `ps4.py`\n",
    "\n",
    "Submit `ps4.py` and the completed version of this notebook `ps4.ipynb` to the `PS4 Code` assignment on Gradescope.\n",
    "\n",
    "**The remaining deliverables should be added to your answer sheet and are listed in each sub-part below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#############################################################################\n",
    "# TODO: Add additional imports\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Raw descriptor matching [15 pts]: \n",
    "\n",
    "In this part, we will write code to allow a user to select a region of interest in one image and then \n",
    "match descriptors from that region with descriptors in another image.\n",
    "\n",
    "We shall display the selected region of interest in the first image (a polygon), and the matched features in the second image.The output should look similar to this:\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/rd9jzz0bd3b8hxz/cv_ps4.png?raw=1\" width=\"700\" height=\"900\"/>\n",
    "\n",
    "> **Note: Do not use a visual vocabulary for this part.**\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Write a script `select_roi.py` that\n",
    "   - loads `twoFrameData.mat`,\n",
    "   - displays 'im1',\n",
    "   - allows a user to select a region of interest in the image,\n",
    "   - saves the selected region (i.e. an Nx2 array of polygon points) to `region.npy`,\n",
    "   - and saves the indicies of the features contained within the selected region to `points.npy`.\n",
    "   \n",
    "> Hint: Read through `loadDataExample.py`. You will find some of the functionality you need in there.\n",
    "\n",
    "2. Implement the `match_descriptors` function as described below.\n",
    "\n",
    "3. Write code in this notebook to\n",
    "   - load `twoFrameData.mat`, `region.npy`, and `points.npy`\n",
    "   - call `match_descriptors` with the subset of descriptors from the selected region\n",
    "   - generate a figure (as above) that displays the selected region in 'im1' and the corresponding feature matches in 'im2'.\n",
    "   \n",
    "\n",
    "#### Deliverables\n",
    "\n",
    "- [ ] The function `match_descriptors` should be included when you export `ps4.py`.\n",
    "- [ ] Add the figure from step 3 to your answer sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_descriptors(desc1, desc2):\n",
    "    \"\"\" Finds the `descriptors2` that best match `descriptors1`\n",
    "    \n",
    "    Inputs:\n",
    "    - desc1: NxD matrix of feature descriptors\n",
    "    - desc2: MxD matrix of feature descriptors\n",
    "\n",
    "    Returns:\n",
    "    - indices: the index of N descriptors from `desc2` that \n",
    "               best match each descriptor in `desc1`\n",
    "    \"\"\"\n",
    "    N = desc1.shape[0]\n",
    "    indices = np.zeros((N,), dtype=\"int64\")\n",
    "    \n",
    "    ############################\n",
    "    # TODO: Add your code here #\n",
    "    ############################\n",
    "    \n",
    "   \n",
    "    ############################\n",
    "    #     END OF YOUR CODE     #\n",
    "    ############################\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# TODO: Write code to complete the steps described above.          #\n",
    "####################################################################\n",
    "\n",
    "####################################################################\n",
    "#                        END OF YOUR CODE                          #\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Visualizing the vocabulary [20 pts]:\n",
    "\n",
    "In this part we will build a visual vocabulary.\n",
    "\n",
    "#### Steps\n",
    "\n",
    "1. Cluster a large, representative random sample of SIFT descriptors from some portion of the frames using k-means. Let the `k` centers be the visual words. The value of `k` is a free parameter. For this data something like `k = 1500` should work, but feel free to play with this parameter. For clustering, refer to `kmeans` function in **sklearn**. \n",
    "\n",
    "   > **Note:** You may run out of memory if you use all the provided SIFT descriptors to build the vocabulary.\n",
    "\n",
    "   Save the cluster centers to `vocabulary.npy` so that you can use the vocabulary again in other parts of the assignment.\n",
    "\n",
    "\n",
    "2. Display example image patches associated with any two of the visual words i.e choose raw SIFT descriptors that are nearest to each of the chosen visual words. Choose the two words such that they are distinct to illustrate what the different words are capturing, and display enough patch examples so the word content is evident (e.g., 25 patches per word). \n",
    "\n",
    "> Refer to the helper functions `getPatchFromSIFTParameters.py` to display patches and `dist2.py` for fast distance computation.\n",
    "\n",
    "\n",
    "3. Describe what you see in your answer sheet\n",
    "\n",
    "#### Deliverables\n",
    "\n",
    "- [ ] Display patches corresponding with two visual words in your answer sheet.\n",
    "- [ ] Discuss the results in your answer sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# TODO: Write code to complete the steps described above.          #\n",
    "####################################################################\n",
    "\n",
    "####################################################################\n",
    "#                        END OF YOUR CODE                          #\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.  Full frame queries [20 pts]:\n",
    "\n",
    "In this part we will use our visual vocabulary to perfom frame queries.\n",
    "\n",
    "#### Steps\n",
    "\n",
    "1. Map an image’s features into its bag-of-words histogram. The histogram for image *$I_j$* is a k-dimensional vector:\n",
    "\n",
    "   $$F(I_j) = [freq_{1,j}, freq_{2,j}, ....., freq_{k,j}]$$\n",
    "\n",
    "   where each entry *$freq_{i,j}$* counts the number of occurrences of the i-th visual word in that image, and `k` is the number of total words in the vocabulary.\n",
    "   \n",
    "   In other words, a single image’s list of `N` **SIFT** descriptors yields a `k-dimensional` bag of words histogram.\n",
    "\n",
    "\n",
    "2. Compute similarity scores. Compare two bag-of-words histograms using the normalized scalar product:\n",
    "\n",
    "   $$S(I_i,I_j) = \\frac{F(I_i) \\cdot F(I_j)}{||F(I_i)||||F(I_j)||} = \\frac{1}{||F(I_i)||||F(I_j)||} \\sum_{m=1}^{k} freq_{m,i}freq_{m,j}$$\n",
    "\n",
    "   where $S()$ is the similarity score. $||F(I_i)||$ is the `L2` norm of $F(I_i)$.\n",
    "\n",
    "\n",
    "3. Sort the similarity scores between a query histogram and the histograms associated with the rest of the images in the video. Pull up the images associated with the `M` most similar examples.\n",
    "\n",
    "\n",
    "4. After testing your code for bag-of-words visual search, choose 3 diﬀerent frames from the entire video dataset to serve as queries. \n",
    "\n",
    "\n",
    "5. Display the `M=5` most similar frames to each of these queries (in rank order) based on the normalized scalar product between their bag of words histograms. \n",
    "\n",
    "\n",
    "6. Explain the results in your answer sheet.\n",
    "\n",
    "#### Deliverables\n",
    "\n",
    "- [ ] The function `calculate_bag_of_words_histogram` should be included when you export `ps4.py`.\n",
    "- [ ] The function `caculate_normalized_scalar_product` should be included when you export `ps4.py`.\n",
    "- [ ] Display `3` different query frames and the `M=5` most similar frames from the video dataset (don't include the query in the results) in your answer sheet.\n",
    "- [ ] Explain the results in your answer sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bag_of_words_histogram(vocabulary, descriptors):\n",
    "    \"\"\" Calculate the bag-of-words histogram for the given frame descriptors.\n",
    "    \n",
    "    Inputs:\n",
    "    - vocabulary: kxd array representing a visual vocabulary\n",
    "    - descriptors: nxd array of frame descriptors\n",
    "    \n",
    "    Outputs:\n",
    "    - histogram: k-dimensional bag-of-words histogram\n",
    "    \"\"\"\n",
    "    k = vocabulary.shape[0]\n",
    "    histogram = np.zeros((k,), dtype=\"int64\")\n",
    "\n",
    "    ############################\n",
    "    # TODO: Add your code here #\n",
    "    ############################\n",
    "    \n",
    "    ############################\n",
    "    #     END OF YOUR CODE     #\n",
    "    ############################\n",
    "\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_normalized_scalar_product(hist1, hist2):\n",
    "    \"\"\" Caculate the normalized scalar product between two histograms.\n",
    "    \n",
    "    Inputs:\n",
    "    - hist1: k-dimensional array\n",
    "    - hist2: k-dimensional array\n",
    "    \n",
    "    Outputs:\n",
    "    - score: the normalized scalar product described above\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    ############################\n",
    "    # TODO: Add your code here #\n",
    "    ############################\n",
    "    \n",
    "    ############################\n",
    "    #     END OF YOUR CODE     #\n",
    "    ############################\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# TODO: Write code to complete the steps described above. Make     #\n",
    "# sure you use your `calculate_bag_of_words_histogram` and         #\n",
    "# `caculate_normalized_scalar_product` functions.                  #\n",
    "####################################################################\n",
    "\n",
    "####################################################################\n",
    "#                        END OF YOUR CODE                          #\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.  Region queries [20 pts]:\n",
    "\n",
    "In this step we will use regions of interest within an image to query frames from the video.\n",
    "\n",
    "#### Steps\n",
    "\n",
    "1. Form a query from a region within a frame. Select a polygonal region interactively with the mouse, and compute a bag of words histogram from only the SIFT descriptors that fall within that region.  Optionally, you may weight it with tf-idf.\n",
    "\n",
    "   > You may want to reuse your `select_roi.py` script here.\n",
    "\n",
    "\n",
    "2. Select your favorite query regions from within 4 frames (which may be diﬀerent than those used above) to demonstrate the retrieved frames when only a portion of the SIFT descriptors are used to form a bag of words. \n",
    "\n",
    "   > Try to include example(s) where the same object is found in the **most similar M frames** but amidst diﬀerent objects or backgrounds, and also **include a failure case**. \n",
    "\n",
    "3. Explain the results, including possible reasons for the failure cases in your answer sheet.\n",
    "\n",
    "#### Deliverables\n",
    "\n",
    "- [ ] Display the selected query region and the `M=5` most similar frames for `4` different queries in your answer sheet.\n",
    "- [ ] Explain the results in your answer sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# TODO: Write code to complete the steps described above.          #\n",
    "####################################################################\n",
    "\n",
    "####################################################################\n",
    "#                        END OF YOUR CODE                          #\n",
    "####################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
